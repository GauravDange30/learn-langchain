{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d581d735-8037-494b-b8c0-375ba61e2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b7afcd-87e6-4909-a749-eb6ec2c557f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic._internal._model_construction.ModelMetaclass"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e537e304-d48c-4bf7-80e3-b1fe214b571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4f0ce-56ff-40bb-b813-7df71b166ef6",
   "metadata": {},
   "source": [
    "## Types of Loader\n",
    "\n",
    "###### PDFLoader\n",
    "###### CSVLoader\n",
    "###### WebBaseLoader\n",
    "###### DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d3eac7-8806-420a-9eb4-d38a6f514049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document # same as above import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f612d3e9-33e0-4c8f-a7b7-b2fdefb6451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(\n",
    "    page_content = \"This is a txt file data\", \n",
    "    metadata={\n",
    "        \"source\":\"example.txt\",\n",
    "        \"pages\": \"5\",\n",
    "        \"author\":\"Gaurav\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8033793e-66b4-480a-b95a-f84035e5f412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': '5', 'author': 'Gaurav'}, page_content='This is a txt file data')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c6b0c84-72c4-4e2f-a66f-0ee2360dc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/Users/gdange/Documents/Personal/Gaurav_Dange_Resume.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9369542-afbc-4f74-a348-9a9000c65bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original documents: 1\n",
      "Chunks created: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'r, Kubernetes, CI/CD, Jenkins, AWS, Git (BitBucket)\\nArchitecture & Tools: Microservices, ETL, Swagger, Postman, Jira, Kibana\\nAI Tools: LLM APIs, RAG, MCP\\nWORK EXPERIENCE\\nProduct Solutions Expert - II May 2025 - Present\\nEightfold - AI Bangalore, India\\n• Serve as the single point of contact and primary Solution Expert for enterprise clients with a combined ACV of\\n$5M, leading end-to-end integrations and owning post–go-live technical support and escalations.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # characters per chunk\n",
    "    chunk_overlap=200,      # overlap to preserve context\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "pdf_chunks = text_splitter.split_documents(pdf_documents)\n",
    "\n",
    "print(f\"Original documents: {len(pdf_documents)}\")\n",
    "print(f\"Chunks created: {len(pdf_chunks)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29d7e80f-ec4f-40d3-85f4-ca56a0235e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpdf_chunks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd3d9c48-6edf-49dc-88d3-a650d65a8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import numpy as np\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01f39daa-ad89-488a-ac6f-65981b5fcac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            print(f\"Loading Embedding model {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model Loaded Successfully. Embedding Dimension is {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error Loading Embedding model {self.model_name} with {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts=List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embedding for list of texts\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "\n",
    "        print(f\"Generating embedding for the texts\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings for the texts with shape {embeddings.shape}\")\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ff8bcc-0827-451c-8da0-c69a27dcc69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embedding model all-MiniLM-L6-v2\n",
      "Model Loaded Successfully. Embedding Dimension is  384\n"
     ]
    }
   ],
   "source": [
    "embeddings_manager = EmbeddingManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5cd9ab-ace7-4ff7-9a01-c66d1a9361a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x35cd01d60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_manager.generate_embeddings(docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674aed32-9cb4-4099-9950-4781d59a6c29",
   "metadata": {},
   "source": [
    "# VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f5251ce-be2c-43d8-8c65-b3fd7a1b9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "\n",
    "    def __init__(self, collection_name:str = \"pdf_documents\", persist_directory : str = \"/Users/gdange/Documents/Personal/VectorStore\"):\n",
    "\n",
    "        self.collection_name=collection_name\n",
    "        self.persist_directory=persist_directory\n",
    "        self.client= None\n",
    "        self.collection=None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize chromadb client and collection\n",
    "        \"\"\"\n",
    "\n",
    "        os.makedirs(self.persist_directory, exist_ok=True)\n",
    "        self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "        \n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name = self.collection_name,\n",
    "            metadata = {\n",
    "                \"description\": \"PDF documents embedding for the RAG\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Vector Store intialized Collection {self.collection_name}\")\n",
    "        print(f\"Existing documents in collection {self.collection.count()}\")\n",
    "\n",
    "    def add_documents(self, documents : List[Any], embeddings : np.ndarray):\n",
    "\n",
    "        if len(documents)!=len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "\n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embeddings) in enumerate(zip(documents, embeddings)):\n",
    "\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index']=i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            embeddings_list.append(embeddings.tolist())\n",
    "        \n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text,\n",
    "                embeddings=embeddings_list\n",
    "            )\n",
    "\n",
    "            print(f\"Sucessfully added {len(documents)} to collection\")\n",
    "        except Exception as e:\n",
    "            raise\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6935701-2cd9-4920-bd85-a79868837ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store intialized Collection pdf_documents\n",
      "Existing documents in collection 0\n"
     ]
    }
   ],
   "source": [
    "vector_store = VectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58b555c7-0261-4e60-85bc-2980e38ea617",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [doc.page_content for doc in pdf_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a6df9e4-7c33-4858-a22c-007193a9cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding for the texts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149decafef68434495234db02ac49911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for the texts with shape (4, 384)\n"
     ]
    }
   ],
   "source": [
    "embeddings  = embeddings_manager.generate_embeddings(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ce8f3ad-a35c-4d01-972c-78fb7ba87638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11325298, -0.02346559, -0.03093507, ..., -0.00713788,\n",
       "        -0.03728819,  0.02549302],\n",
       "       [-0.06875946,  0.00552643,  0.02087624, ..., -0.05638217,\n",
       "        -0.0034661 ,  0.04931682],\n",
       "       [-0.05549109,  0.01490006,  0.04847825, ...,  0.00833948,\n",
       "        -0.00590183,  0.02723115],\n",
       "       [-0.07883993,  0.01037853, -0.07615634, ..., -0.00950061,\n",
       "        -0.01788303,  0.06012804]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa81aee0-8455-4f50-b9d6-169f08abab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 4 documents to vector store...\n",
      "Sucessfully added 4 to collection\n"
     ]
    }
   ],
   "source": [
    "vector_store.add_documents(pdf_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f1a330bb-a668-4b4a-92f9-0705ce311dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x35ec025b0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3bbdaa-d44b-4ab0-8b56-17b924879f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
